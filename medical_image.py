import openai
import streamlit as st
from PIL import Image
import torchxrayvision as xrv
from torchvision import transforms
import torch

# Initialize session state for OpenAI API Key
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state.OPENAI_API_KEY = None

# Sidebar for API Key Configuration
with st.sidebar:
    st.title("üîß Configuration")
    if not st.session_state.OPENAI_API_KEY:
        api_key = st.text_input("Enter your OpenAI API Key:", type="password")
        if api_key:
            st.session_state.OPENAI_API_KEY = api_key
            st.success("API Key saved!")
            st.rerun()
    else:
        st.success("API Key is configured")

# Main Application
st.title("üè• Medical Imaging Diagnosis Agent")

# Image Upload
uploaded_file = st.file_uploader("Upload Medical Image (Chest X-ray)", type=["jpg", "jpeg", "png"])

# Load pre-trained medical imaging model (torchxrayvision)
@st.cache_resource
def load_medical_model():
    model = xrv.models.get_model("resnet50-res512-all")  # Use the model name with weights
    model.eval()
    return model

model = load_medical_model()

# Preprocess function for X-ray images
def preprocess_xray(image):
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),  # Convert to single channel
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize
    ])
    return transform(image)

if uploaded_file:
    # Display the image
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Uploaded Medical Image", use_container_width=True)

    # Analyze Image Button
    analyze_button = st.button("üîç Analyze Image")

    if analyze_button:
        with st.spinner("Analyzing image..."):
            try:
                # Step 1: Preprocess the image and run the X-ray model
                processed_image = preprocess_xray(image)
                processed_image = processed_image.unsqueeze(0)  # Add batch dimension
                outputs = model(processed_image)

                # Extract predictions
                diseases = model.pathologies
                predictions = torch.sigmoid(outputs[0]).detach().numpy()

                # Select top predictions
                top_diseases = sorted(
                    zip(diseases, predictions),
                    key=lambda x: x[1],
                    reverse=True
                )[:3]

                extracted_text = "\n".join([f"{disease}: {confidence:.2f}" for disease, confidence in top_diseases])

                # Step 2: Use OpenAI for further analysis
                openai.api_key = st.session_state.OPENAI_API_KEY
                response = openai.ChatCompletion.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "You are a medical imaging expert."},
                        {"role": "user", "content": f"Analyze the following findings from a chest X-ray:\n{extracted_text}"}
                    ],
                )

                # Step 3: Display results
                st.markdown("### üìã Analysis Results")
                st.markdown(response.choices[0]["message"]["content"])
                st.caption(
                    "Note: This analysis is generated by AI and should be reviewed by qualified healthcare professionals."
                )
            except Exception as e:
                st.error(f"Error during analysis: {e}")
